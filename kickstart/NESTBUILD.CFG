#############################
## Kickstart Configuration ##
#############################

## Accept the VMware End User License Agreement
vmaccepteula

## Uncomment this line to clear paritions on all connected disks. This will also blow away VMFS partitions. 
#clearpart --alldrives --overwritevmfs

#### Uncomment ONE install line shown below. Each line is an isolated example to be chosen based off of your unique situation.
## Install to the first physical disk and overwrite any existing VMFS partitions
install --firstdisk --overwritevmfs

## Install to the disk whose name contains the string 'SuperMicro SSD'.
#install --firstdisk='SuperMicro SSD' --overwritevmfs

## Install upon the disk which currently possesses an ESXi installtion (overwrite previous server).
#install --firstdisk=localesx --overwritevmfs
####

## Set the root password
rootpw VMware123!

## Host Network Settings (Set IP, Assign Management VLAN, and create the VM Portgroup as required by VCF. Uncomment based on DHCP or Static assignment)
network --bootproto=dhcp --vlanid=41 --addvmportgroup=1
#network --bootproto=static --addvmportgroup=1 --ip=10.1.1.14 --netmask=255.255.255.0 --gateway=10.1.1.1 --nameserver=10.0.1.100 --hostname=reptile

## Reboot without user interactivity
reboot

##########################################
## Post-Install Configuration (BusyBox) ##
##########################################

%firstboot --interpreter=busybox

## Set DNS search suffix
esxcli network ip dns search add -d lab.altitudeautomations.com

## If DHCP is selected (as is the case for nested installs) ensure this line is UNCOMMENTED. This sets the hostname of the server based off of the assigned reservation.
for i in `esxcli network ip interface ipv4 get | grep vmk0 | awk '{ print $2 }'`; do esxcli system hostname set --fqdn=`nslookup $i | grep name | awk '{ print $4 }'`; done

## If DHCP is selected, ensure this line IS COMMENTED. This sets the FQDN of the host, which is necessary for the certificate operation at the end of this file.
#esxcli system hostname set --fqdn=reptile.lab.altitudeautomations.com

# Enable and start both Remote ESXi shell (SSH) and local ESXi Shell
vim-cmd hostsvc/enable_ssh
vim-cmd hostsvc/start_ssh
vim-cmd hostsvc/enable_esx_shell
vim-cmd hostsvc/start_esx_shell

# supress ESXi Shell shell warning and disable CEIP
esxcli system settings advanced set -o /UserVars/SuppressShellWarning -i 1
esxcli system settings advanced set -o /UserVars/HostClientCEIPOptIn -i 2

################################
## vSwitch/VMK0 configuration ##
################################

## Unlink vmnic0 and replace with vmnic6 on vSwitch0 (Necessary when vmnic0 is not the connected pnic on a physical host)
#esxcli network vswitch standard uplink remove --uplink-name=vmnic0 --vswitch-name=vSwitch0
#esxcli network vswitch standard uplink add --uplink-name=vmnic6 --vswitch-name=vSwitch0

## Set management VLAN to 41
esxcli network vswitch standard portgroup set -p 'Management Network' --vlan-id 41

## configure mtu + cdp + security on vSwitch0
esxcli network vswitch standard set --mtu 9000 --cdp-status listen --vswitch-name vSwitch0

## Configure vmk0 for jumbo frames
esxcli network ip interface set --interface-name vmk0 --mtu 9000

## Configure 'VM Network' portgroup to use v41 in accordance with VCF expected behavior
esxcli network vswitch standard portgroup set -p 'VM Network' --vlan-id 41

##################################
## Miscellaneous Configurations ##
##################################

## Disable IPv6 for VMkernel interfaces (DOES NOT TAKE EFFECT UNTIL REBOOT)
esxcli system module parameters set -m tcpip4 -p ipv6=0
esxcli network ip set --ipv6-enabled=false

## Reset NTP settings to default, set our NTP servers to match VCF config, enable NTP daemon
esxcli system ntp set -r
esxcli system ntp set -s pool.ntp.org -s north-america.pool.ntp.org
esxcli system ntp set -e yes

## Check if cache/capacity disks are already in use by previous VSAN cluster. If yes, destroy the VSAN disk group so they are free for new deployment. If no, do nothing.
## NOTE: This line assumes only ONE disk group per host for lab purposes. If you intend to use it on an enterprise server with more than 1 disk group, remove the '-m 1' within the grep block.
if [[ `esxcli vsan storage list | wc -c` != 0 ]]; then for i in `esxcli vsan storage list | grep 'VSAN Disk Group UUID' -m 1 | awk '{print $5}'`; do esxcli vsan storage remove -u $i; done fi

## Mark the second and third disks (VSAN Cache and Capacity, respectively) as SSD's
esxcli storage hpp device set -d mpx.vmhba1:C0:T0:L0 -M true
esxcli storage hpp device set -d mpx.vmhba2:C0:T0:L0 -M true

## Set the isCapacityFlash flag to true on the third (VSAN Capacity) disk
esxcli vsan storage tag add -t capacityFlash -d mpx.vmhba2:C0:T0:L0

## Regenerate self-signed certificate with the new FQDN hostname and restart services before commissioning into VCF
/sbin/generate-certificates
/etc/init.d/hostd restart && /etc/init.d/vpxa restart

### DONE ###